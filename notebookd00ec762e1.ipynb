{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa004067",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:09.772465Z",
     "iopub.status.busy": "2025-02-05T12:52:09.772253Z",
     "iopub.status.idle": "2025-02-05T12:52:09.776366Z",
     "shell.execute_reply": "2025-02-05T12:52:09.775826Z"
    },
    "papermill": {
     "duration": 0.013957,
     "end_time": "2025-02-05T12:52:09.777569",
     "exception": false,
     "start_time": "2025-02-05T12:52:09.763612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import shutil\n",
    "\n",
    "# def extract_frames_from_videos(video_folder, output_folder, fps=2):\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     for category in ['drowsiness', 'not drowsiness']:\n",
    "#         input_category_path = os.path.join(video_folder, category)\n",
    "#         output_category_path = os.path.join(output_folder, category)\n",
    "        \n",
    "#         if not os.path.exists(output_category_path):\n",
    "#             os.makedirs(output_category_path)\n",
    "        \n",
    "#         for video_file in os.listdir(input_category_path):\n",
    "#             video_path = os.path.join(input_category_path, video_file)\n",
    "#             if not video_file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "#                 continue\n",
    "            \n",
    "#             cap = cv2.VideoCapture(video_path)\n",
    "#             frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#             frame_interval = max(1, frame_rate // fps)\n",
    "#             count = 0\n",
    "#             frame_count = 0\n",
    "            \n",
    "#             while cap.isOpened():\n",
    "#                 ret, frame = cap.read()\n",
    "#                 if not ret:\n",
    "#                     break\n",
    "                \n",
    "#                 if count % frame_interval == 0:\n",
    "#                     image_name = f\"{os.path.splitext(video_file)[0]}_frame{frame_count}.jpg\"\n",
    "#                     image_path = os.path.join(output_category_path, image_name)\n",
    "#                     cv2.imwrite(image_path, frame)\n",
    "#                     frame_count += 1\n",
    "                \n",
    "#                 count += 1\n",
    "#             cap.release()\n",
    "            \n",
    "\n",
    "# def copy_images(source_folder, dest_folder):\n",
    "#     if not os.path.exists(dest_folder):\n",
    "#         os.makedirs(dest_folder)\n",
    "    \n",
    "#     for file in os.listdir(source_folder):\n",
    "#         source_path = os.path.join(source_folder, file)\n",
    "#         dest_path = os.path.join(dest_folder, file)\n",
    "        \n",
    "#         if os.path.isfile(source_path):\n",
    "#             shutil.copy(source_path, dest_path)\n",
    "            \n",
    "# # video_folder = \"/kaggle/input/sust-ddd/SUST Driver Drowsiness Dataset\"\n",
    "# # output_folder = \"sust-ddd\"\n",
    "# # extract_frames_from_videos(video_folder, output_folder)\n",
    "\n",
    "# copy_images(\"/kaggle/input/mrl-eye-dataset/mrleyedataset/Close-Eyes\", \"sust-ddd/drowsiness\")\n",
    "# copy_images(\"/kaggle/input/mrl-eye-dataset/mrleyedataset/Open-Eyes\", \"sust-ddd/not drowsiness\")\n",
    "\n",
    "# copy_images(\"/kaggle/input/driver-drowsiness-dataset-ddd/Driver Drowsiness Dataset (DDD)/Drowsy\", \"sust-ddd/drowsiness\")\n",
    "# copy_images(\"/kaggle/input/driver-drowsiness-dataset-ddd/Driver Drowsiness Dataset (DDD)/Non Drowsy\", \"sust-ddd/not drowsiness\")\n",
    "\n",
    "# print(\"Completed1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97cd4e7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:09.792128Z",
     "iopub.status.busy": "2025-02-05T12:52:09.791936Z",
     "iopub.status.idle": "2025-02-05T12:52:09.794958Z",
     "shell.execute_reply": "2025-02-05T12:52:09.794354Z"
    },
    "papermill": {
     "duration": 0.011444,
     "end_time": "2025-02-05T12:52:09.796093",
     "exception": false,
     "start_time": "2025-02-05T12:52:09.784649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# def split_dataset(input_folder, output_folder, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     for category in ['drowsiness', 'not drowsiness']:\n",
    "#         category_path = os.path.join(input_folder, category)\n",
    "#         images = os.listdir(category_path)\n",
    "#         random.shuffle(images)\n",
    "        \n",
    "#         train_split = int(len(images) * train_ratio)\n",
    "#         val_split = int(len(images) * (train_ratio + val_ratio))\n",
    "        \n",
    "#         sets = {'train': images[:train_split], 'val': images[train_split:val_split], 'test': images[val_split:]}\n",
    "        \n",
    "#         for split, image_list in sets.items():\n",
    "#             split_path = os.path.join(output_folder, split, category)\n",
    "#             if not os.path.exists(split_path):\n",
    "#                 os.makedirs(split_path)\n",
    "            \n",
    "#             for image in image_list:\n",
    "#                 src_path = os.path.join(category_path, image)\n",
    "#                 dest_path = os.path.join(split_path, image)\n",
    "#                 shutil.copy(src_path, dest_path)\n",
    "                \n",
    "# input_folder = \"sust-ddd\"\n",
    "# output_folder = \"sust-ddd-split\"\n",
    "# split_dataset(input_folder, output_folder)\n",
    "# print(\"Completed1\")\n",
    "# print(\"Training Starts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24ab3e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:09.810474Z",
     "iopub.status.busy": "2025-02-05T12:52:09.810285Z",
     "iopub.status.idle": "2025-02-05T12:52:09.812884Z",
     "shell.execute_reply": "2025-02-05T12:52:09.812289Z"
    },
    "papermill": {
     "duration": 0.010953,
     "end_time": "2025-02-05T12:52:09.813992",
     "exception": false,
     "start_time": "2025-02-05T12:52:09.803039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install facenet_pytorch\n",
    "# !pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cec3392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:09.828287Z",
     "iopub.status.busy": "2025-02-05T12:52:09.828099Z",
     "iopub.status.idle": "2025-02-05T12:52:26.584380Z",
     "shell.execute_reply": "2025-02-05T12:52:26.583309Z"
    },
    "papermill": {
     "duration": 16.765102,
     "end_time": "2025-02-05T12:52:26.585940",
     "exception": false,
     "start_time": "2025-02-05T12:52:09.820838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\r\n",
      "  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\r\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\r\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.5)\r\n",
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\r\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\r\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\r\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\r\n",
      "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2.4.1)\r\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\r\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\r\n",
      "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2->mediapipe) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2->mediapipe) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2->mediapipe) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2->mediapipe) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2->mediapipe) (2024.2.0)\r\n",
      "Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\r\n",
      "Installing collected packages: protobuf, sounddevice, mediapipe\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.6 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed mediapipe-0.10.20 protobuf-4.25.6 sounddevice-0.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d8f0f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:26.603092Z",
     "iopub.status.busy": "2025-02-05T12:52:26.602833Z",
     "iopub.status.idle": "2025-02-05T12:52:26.606669Z",
     "shell.execute_reply": "2025-02-05T12:52:26.605918Z"
    },
    "papermill": {
     "duration": 0.013792,
     "end_time": "2025-02-05T12:52:26.608023",
     "exception": false,
     "start_time": "2025-02-05T12:52:26.594231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Define paths\n",
    "# input_dir = \"/kaggle/input/sust-ddd/SUST Driver Drowsiness Dataset\"\n",
    "# output_dir = \"/kaggle/working/extracted_faces\"\n",
    "\n",
    "# # Ensure output directories exist\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# os.makedirs(f\"{output_dir}/drowsiness\", exist_ok=True)\n",
    "# os.makedirs(f\"{output_dir}/non-drowsiness\", exist_ok=True)\n",
    "\n",
    "# # Initialize MediaPipe face detector\n",
    "# mp_face_detection = mp.solutions.face_detection\n",
    "# face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "# # Function to extract faces with margin\n",
    "# def extract_faces(video_path, output_folder, margin=50, frame_skip=5):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     frame_count = 0\n",
    "#     saved_count = 0\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Process every nth frame\n",
    "#         if frame_count % frame_skip == 0:\n",
    "#             img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             results = face_detection.process(img_rgb)\n",
    "            \n",
    "#             if results.detections:\n",
    "#                 for detection in results.detections:\n",
    "#                     bboxC = detection.location_data.relative_bounding_box\n",
    "#                     h, w, _ = frame.shape\n",
    "#                     x1 = int(bboxC.xmin * w) - margin\n",
    "#                     y1 = int(bboxC.ymin * h) - margin\n",
    "#                     x2 = int((bboxC.xmin + bboxC.width) * w) + margin\n",
    "#                     y2 = int((bboxC.ymin + bboxC.height) * h) + margin\n",
    "\n",
    "#                     # Ensure bounding box stays within frame\n",
    "#                     x1, y1 = max(0, x1), max(0, y1)\n",
    "#                     x2, y2 = min(w, x2), min(h, y2)\n",
    "\n",
    "#                     face = frame[y1:y2, x1:x2]\n",
    "                    \n",
    "#                     if face.size > 0:\n",
    "#                         save_path = os.path.join(output_folder, f\"frame_{saved_count:04d}.jpg\")\n",
    "#                         cv2.imwrite(save_path, face)\n",
    "#                         saved_count += 1\n",
    "        \n",
    "#         frame_count += 1\n",
    "\n",
    "#     cap.release()\n",
    "\n",
    "# # Process each video in both categories\n",
    "# for category in [\"drowsiness\", \"not drowsiness\"]:\n",
    "#     category_path = os.path.join(input_dir, category)\n",
    "#     output_folder = os.path.join(output_dir, category.replace(\" \", \"-\"))  # Replace spaces\n",
    "    \n",
    "#     for video_file in tqdm(os.listdir(category_path), desc=f\"Processing {category} videos\"):\n",
    "#         video_path = os.path.join(category_path, video_file)\n",
    "#         extract_faces(video_path, output_folder)\n",
    "\n",
    "# print(\"Face extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb73f3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:26.624643Z",
     "iopub.status.busy": "2025-02-05T12:52:26.624400Z",
     "iopub.status.idle": "2025-02-05T12:52:26.627873Z",
     "shell.execute_reply": "2025-02-05T12:52:26.627230Z"
    },
    "papermill": {
     "duration": 0.012861,
     "end_time": "2025-02-05T12:52:26.628979",
     "exception": false,
     "start_time": "2025-02-05T12:52:26.616118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Define paths\n",
    "# input_dir = \"/kaggle/input/sust-ddd/SUST Driver Drowsiness Dataset\"\n",
    "# output_dir = \"/kaggle/working/extracted_faces\"\n",
    "\n",
    "# # Ensure output directories exist\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# os.makedirs(f\"{output_dir}/drowsiness\", exist_ok=True)\n",
    "# os.makedirs(f\"{output_dir}/non-drowsiness\", exist_ok=True)\n",
    "\n",
    "# # Initialize MediaPipe face detector\n",
    "# mp_face_detection = mp.solutions.face_detection\n",
    "# face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "# # Function to extract faces with larger coverage and save in respective folders\n",
    "# def extract_faces(video_path, output_folder, frame_skip=5):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     frame_count = 0\n",
    "#     saved_count = 0\n",
    "#     video_name = os.path.splitext(os.path.basename(video_path))[0]  # Extract video name\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Process every nth frame\n",
    "#         if frame_count % frame_skip == 0:\n",
    "#             img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             results = face_detection.process(img_rgb)\n",
    "            \n",
    "#             if results.detections:\n",
    "#                 for detection in results.detections:\n",
    "#                     bboxC = detection.location_data.relative_bounding_box\n",
    "#                     h, w, _ = frame.shape\n",
    "#                     x_min, y_min = int(bboxC.xmin * w), int(bboxC.ymin * h)\n",
    "#                     x_max, y_max = int((bboxC.xmin + bboxC.width) * w), int((bboxC.ymin + bboxC.height) * h)\n",
    "\n",
    "#                     # Calculate dynamic margin (30% of face size)\n",
    "#                     margin_x = int(0.3 * (x_max - x_min))\n",
    "#                     margin_y = int(0.3 * (y_max - y_min))\n",
    "\n",
    "#                     # Apply margin\n",
    "#                     x1, y1 = max(0, x_min - margin_x), max(0, y_min - margin_y)\n",
    "#                     x2, y2 = min(w, x_max + margin_x), min(h, y_max + margin_y)\n",
    "\n",
    "#                     face = frame[y1:y2, x1:x2]\n",
    "                    \n",
    "#                     if face.size > 0:\n",
    "#                         save_path = os.path.join(output_folder, f\"{video_name}_frame_{saved_count:04d}.jpg\")\n",
    "#                         cv2.imwrite(save_path, face)\n",
    "#                         saved_count += 1\n",
    "        \n",
    "#         frame_count += 1\n",
    "\n",
    "#     cap.release()\n",
    "\n",
    "# # Process each video in both categories and save correctly\n",
    "# for category in [\"drowsiness\", \"not drowsiness\"]:\n",
    "#     category_path = os.path.join(input_dir, category)\n",
    "#     output_folder = os.path.join(output_dir, category.replace(\" \", \"-\"))  # Ensure folder name is correct\n",
    "    \n",
    "#     for video_file in tqdm(os.listdir(category_path), desc=f\"Processing {category} videos\"):\n",
    "#         video_path = os.path.join(category_path, video_file)\n",
    "#         extract_faces(video_path, output_folder)\n",
    "\n",
    "# print(\"Face extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addd2c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:26.645284Z",
     "iopub.status.busy": "2025-02-05T12:52:26.645093Z",
     "iopub.status.idle": "2025-02-05T12:52:26.648131Z",
     "shell.execute_reply": "2025-02-05T12:52:26.647563Z"
    },
    "papermill": {
     "duration": 0.012347,
     "end_time": "2025-02-05T12:52:26.649191",
     "exception": false,
     "start_time": "2025-02-05T12:52:26.636844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# # Define paths\n",
    "# input_dir = \"/kaggle/working/extracted_faces\"\n",
    "# output_dir = \"/kaggle/working/split_data\"\n",
    "\n",
    "# # Train-test split ratio\n",
    "# train_ratio = 0.8  \n",
    "\n",
    "# # Create train and test directories\n",
    "# for split in [\"train\", \"test\"]:\n",
    "#     for category in [\"drowsiness\", \"non-drowsiness\"]:\n",
    "#         os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
    "\n",
    "# # Function to split data\n",
    "# def split_data():\n",
    "#     for category in [\"drowsiness\", \"non-drowsiness\"]:\n",
    "#         image_dir = os.path.join(input_dir, category)\n",
    "#         images = os.listdir(image_dir)\n",
    "\n",
    "#         # Shuffle images randomly\n",
    "#         random.shuffle(images)\n",
    "\n",
    "#         # Split into train and test\n",
    "#         split_idx = int(len(images) * train_ratio)\n",
    "#         train_images = images[:split_idx]\n",
    "#         test_images = images[split_idx:]\n",
    "\n",
    "#         # Move files to respective folders\n",
    "#         for img in train_images:\n",
    "#             src = os.path.join(image_dir, img)\n",
    "#             dst = os.path.join(output_dir, \"train\", category, img)\n",
    "#             shutil.move(src, dst)  # Use move instead of copy\n",
    "\n",
    "#         for img in test_images:\n",
    "#             src = os.path.join(image_dir, img)\n",
    "#             dst = os.path.join(output_dir, \"test\", category, img)\n",
    "#             shutil.move(src, dst)  # Use move instead of copy\n",
    "\n",
    "# # Run the split function\n",
    "# split_data()\n",
    "# print(\"Data split complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610244ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:26.665679Z",
     "iopub.status.busy": "2025-02-05T12:52:26.665437Z",
     "iopub.status.idle": "2025-02-05T12:52:29.985259Z",
     "shell.execute_reply": "2025-02-05T12:52:29.984405Z"
    },
    "papermill": {
     "duration": 3.329913,
     "end_time": "2025-02-05T12:52:29.987013",
     "exception": false,
     "start_time": "2025-02-05T12:52:26.657100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.20)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\r\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\r\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.5)\r\n",
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\r\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.6)\r\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\r\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2->mediapipe) (2.4.1)\r\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\r\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\r\n",
      "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2->mediapipe) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2->mediapipe) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2->mediapipe) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2->mediapipe) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2->mediapipe) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba65d232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T12:52:30.005356Z",
     "iopub.status.busy": "2025-02-05T12:52:30.005044Z",
     "iopub.status.idle": "2025-02-05T13:26:03.958047Z",
     "shell.execute_reply": "2025-02-05T13:26:03.957139Z"
    },
    "papermill": {
     "duration": 2013.963207,
     "end_time": "2025-02-05T13:26:03.959482",
     "exception": false,
     "start_time": "2025-02-05T12:52:29.996275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing drowsiness videos: 100%|██████████| 975/975 [15:09<00:00,  1.07it/s]\n",
      "Processing not drowsiness videos: 100%|██████████| 1099/1099 [18:12<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face extraction and train-test split complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Define Paths\n",
    "input_dir = \"/kaggle/input/sust-ddd/SUST Driver Drowsiness Dataset\"\n",
    "output_dir = \"/kaggle/working/split_data\"\n",
    "\n",
    "# Train-test split ratio\n",
    "train_ratio = 0.8  \n",
    "\n",
    "# Create train and test directories\n",
    "for split in [\"train\", \"test\"]:\n",
    "    for category in [\"drowsiness\", \"not-drowsiness\"]:\n",
    "        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
    "\n",
    "# Initialize MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "# Function to Extract Faces & Save Directly into Train/Test Folders\n",
    "def extract_and_save_faces(video_path, category):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    saved_faces = []\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]  # Extract video name\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process every 5th frame for efficiency\n",
    "        if frame_count % 5 == 0:\n",
    "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(img_rgb)\n",
    "            \n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    h, w, _ = frame.shape\n",
    "                    x_min, y_min = int(bboxC.xmin * w), int(bboxC.ymin * h)\n",
    "                    x_max, y_max = int((bboxC.xmin + bboxC.width) * w), int((bboxC.ymin + bboxC.height) * h)\n",
    "\n",
    "                    # Add a margin (30% of face size)\n",
    "                    margin_x = int(0.3 * (x_max - x_min))\n",
    "                    margin_y = int(0.3 * (y_max - y_min))\n",
    "\n",
    "                    # Apply margin while keeping within image bounds\n",
    "                    x1, y1 = max(0, x_min - margin_x), max(0, y_min - margin_y)\n",
    "                    x2, y2 = min(w, x_max + margin_x), min(h, y_max + margin_y)\n",
    "\n",
    "                    face = frame[y1:y2, x1:x2]\n",
    "\n",
    "                    if face.size > 0:\n",
    "                        saved_faces.append(face)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Shuffle and split into train/test\n",
    "    random.shuffle(saved_faces)\n",
    "    split_idx = int(len(saved_faces) * train_ratio)\n",
    "    train_faces = saved_faces[:split_idx]\n",
    "    test_faces = saved_faces[split_idx:]\n",
    "\n",
    "    # Save faces\n",
    "    for i, face in enumerate(train_faces):\n",
    "        save_path = os.path.join(output_dir, \"train\", category, f\"{video_name}_frame_{i:04d}.jpg\")\n",
    "        cv2.imwrite(save_path, face)\n",
    "\n",
    "    for i, face in enumerate(test_faces):\n",
    "        save_path = os.path.join(output_dir, \"test\", category, f\"{video_name}_frame_{i:04d}.jpg\")\n",
    "        cv2.imwrite(save_path, face)\n",
    "\n",
    "# Process each video in both categories\n",
    "for category in [\"drowsiness\", \"not drowsiness\"]:\n",
    "    category_path = os.path.join(input_dir, category)\n",
    "    save_category = category.replace(\" \", \"-\")  # Ensure valid folder naming\n",
    "\n",
    "    for video_file in tqdm(os.listdir(category_path), desc=f\"Processing {category} videos\"):\n",
    "        video_path = os.path.join(category_path, video_file)\n",
    "        extract_and_save_faces(video_path, save_category)\n",
    "\n",
    "print(\"Face extraction and train-test split complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0047f903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T13:26:04.158853Z",
     "iopub.status.busy": "2025-02-05T13:26:04.158220Z",
     "iopub.status.idle": "2025-02-05T16:35:39.934610Z",
     "shell.execute_reply": "2025-02-05T16:35:39.933675Z"
    },
    "papermill": {
     "duration": 11375.902257,
     "end_time": "2025-02-05T16:35:39.960588",
     "exception": false,
     "start_time": "2025-02-05T13:26:04.058331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98774 images belonging to 2 classes.\n",
      "Found 24795 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1164s\u001b[0m 3s/step - accuracy: 0.6725 - loss: 0.6011 - val_accuracy: 0.7877 - val_loss: 0.4786\n",
      "Epoch 2/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1129s\u001b[0m 3s/step - accuracy: 0.7787 - loss: 0.4806 - val_accuracy: 0.7981 - val_loss: 0.4549\n",
      "Epoch 3/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1128s\u001b[0m 3s/step - accuracy: 0.7952 - loss: 0.4522 - val_accuracy: 0.8091 - val_loss: 0.4302\n",
      "Epoch 4/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1138s\u001b[0m 3s/step - accuracy: 0.8033 - loss: 0.4321 - val_accuracy: 0.8139 - val_loss: 0.4169\n",
      "Epoch 5/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1145s\u001b[0m 3s/step - accuracy: 0.8083 - loss: 0.4204 - val_accuracy: 0.8186 - val_loss: 0.4074\n",
      "Epoch 6/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1129s\u001b[0m 3s/step - accuracy: 0.8134 - loss: 0.4108 - val_accuracy: 0.8196 - val_loss: 0.4015\n",
      "Epoch 7/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1128s\u001b[0m 3s/step - accuracy: 0.8148 - loss: 0.4053 - val_accuracy: 0.8172 - val_loss: 0.4040\n",
      "Epoch 8/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1144s\u001b[0m 3s/step - accuracy: 0.8208 - loss: 0.3976 - val_accuracy: 0.8163 - val_loss: 0.4077\n",
      "Epoch 9/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1126s\u001b[0m 3s/step - accuracy: 0.8197 - loss: 0.3944 - val_accuracy: 0.8217 - val_loss: 0.3914\n",
      "Epoch 10/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1133s\u001b[0m 3s/step - accuracy: 0.8236 - loss: 0.3888 - val_accuracy: 0.8257 - val_loss: 0.3868\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define Paths\n",
    "data_dir = \"/kaggle/working/split_data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load Train & Test Data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load Pretrained MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base model layers\n",
    "\n",
    "# Custom Head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)  # Binary Classification (Drowsy vs Non-Drowsy)\n",
    "\n",
    "# Create Model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(train_generator, validation_data=test_generator, epochs=EPOCHS)\n",
    "\n",
    "# Save Model as .h5\n",
    "model.save(\"/kaggle/working/mobilenetv2_drowsiness.h5\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab9bbc62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:35:40.538032Z",
     "iopub.status.busy": "2025-02-05T16:35:40.537434Z",
     "iopub.status.idle": "2025-02-05T16:35:45.111151Z",
     "shell.execute_reply": "2025-02-05T16:35:45.110227Z"
    },
    "papermill": {
     "duration": 4.86362,
     "end_time": "2025-02-05T16:35:45.112841",
     "exception": false,
     "start_time": "2025-02-05T16:35:40.249221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\r\n",
      "Collecting tf2onnx\r\n",
      "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.32.3)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.17.0)\r\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\r\n",
      "Collecting protobuf>=3.20.2 (from onnx)\r\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.12.14)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->onnx) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->onnx) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf, tf2onnx\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 4.25.6\r\n",
      "    Uninstalling protobuf-4.25.6:\r\n",
      "      Successfully uninstalled protobuf-4.25.6\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "mediapipe 0.10.20 requires protobuf<5,>=4.25.3, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3 tf2onnx-1.16.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx tf2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fad89e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:35:45.684741Z",
     "iopub.status.busy": "2025-02-05T16:35:45.684373Z",
     "iopub.status.idle": "2025-02-05T16:35:49.949162Z",
     "shell.execute_reply": "2025-02-05T16:35:49.948070Z"
    },
    "papermill": {
     "duration": 4.55162,
     "end_time": "2025-02-05T16:35:49.950679",
     "exception": false,
     "start_time": "2025-02-05T16:35:45.399059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully saved in ONNX format at /kaggle/working/mobilenetv2_drowsiness.onnx\n"
     ]
    }
   ],
   "source": [
    "import tf2onnx\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the input signature. This should match your model's input shape.\n",
    "spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name=\"input\"),)\n",
    "\n",
    "# Specify the output file path for the ONNX model.\n",
    "output_path = \"/kaggle/working/mobilenetv2_drowsiness.onnx\"\n",
    "\n",
    "# Convert the Keras model to ONNX.\n",
    "model_proto, _ = tf2onnx.convert.from_keras(\n",
    "    model,         # your trained model\n",
    "    input_signature=spec,\n",
    "    opset=13,      # You can adjust the ONNX opset version if needed.\n",
    "    output_path=output_path\n",
    ")\n",
    "\n",
    "print(\"Model successfully saved in ONNX format at\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da120456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:35:50.595440Z",
     "iopub.status.busy": "2025-02-05T16:35:50.595054Z",
     "iopub.status.idle": "2025-02-05T16:35:50.600322Z",
     "shell.execute_reply": "2025-02-05T16:35:50.599418Z"
    },
    "papermill": {
     "duration": 0.294,
     "end_time": "2025-02-05T16:35:50.601679",
     "exception": false,
     "start_time": "2025-02-05T16:35:50.307679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torchvision\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms, models\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Paths\n",
    "# data_dir = \"/kaggle/working/split_data\"\n",
    "# train_dir = os.path.join(data_dir, \"train\")\n",
    "# test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# # Hyperparameters\n",
    "# batch_size = 64\n",
    "# num_epochs = 20\n",
    "# learning_rate = 0.001\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Data Augmentation & Normalization\n",
    "# transform = {\n",
    "#     \"train\": transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomRotation(10),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     \"test\": transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "# }\n",
    "\n",
    "# # Load Datasets\n",
    "# train_dataset = datasets.ImageFolder(train_dir, transform=transform[\"train\"])\n",
    "# test_dataset = datasets.ImageFolder(test_dir, transform=transform[\"test\"])\n",
    "\n",
    "# # Dataloaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# # Load Pretrained MobileNetV2\n",
    "# model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# # Modify classifier for 2 classes (Drowsy & Non-Drowsy)\n",
    "# model.classifier[1] = nn.Linear(model.last_channel, 2)\n",
    "\n",
    "# # Move model to GPU if available\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Loss and Optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Training Function\n",
    "# def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "#     model.train()\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         running_loss = 0.0\n",
    "#         correct, total = 0, 0\n",
    "        \n",
    "#         for images, labels in train_loader:\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             running_loss += loss.item()\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             correct += (preds == labels).sum().item()\n",
    "#             total += labels.size(0)\n",
    "\n",
    "#         epoch_loss = running_loss / len(train_loader)\n",
    "#         epoch_acc = correct / total * 100\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "    \n",
    "#     print(\"Training Complete!\")\n",
    "\n",
    "# # Run Training\n",
    "# train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# # Save the Model\n",
    "# torch.save(model.state_dict(), \"/kaggle/working/mobilenetv2_drowsiness.pth\")\n",
    "# print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0049cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:35:51.180282Z",
     "iopub.status.busy": "2025-02-05T16:35:51.179968Z",
     "iopub.status.idle": "2025-02-05T16:35:51.184123Z",
     "shell.execute_reply": "2025-02-05T16:35:51.183210Z"
    },
    "papermill": {
     "duration": 0.294595,
     "end_time": "2025-02-05T16:35:51.185499",
     "exception": false,
     "start_time": "2025-02-05T16:35:50.890904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define paths\n",
    "# data_dir = \"sust-ddd-split\"\n",
    "# img_size = (224, 224)\n",
    "# batch_size = 128\n",
    "\n",
    "# # Data augmentation and preprocessing\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rescale=1.0/255,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     validation_split=0.2\n",
    "# )\n",
    "\n",
    "# train_data = datagen.flow_from_directory(\n",
    "#     os.path.join(data_dir, \"train\"),\n",
    "#     target_size=img_size,\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='binary'\n",
    "# )\n",
    "\n",
    "# val_data = datagen.flow_from_directory(\n",
    "#     os.path.join(data_dir, \"val\"),\n",
    "#     target_size=img_size,\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='binary'\n",
    "# )\n",
    "\n",
    "# # Pretrained Model - MobileNetV2\n",
    "# base_model = keras.applications.MobileNetV2(input_shape=(*img_size, 3), include_top=False, weights=\"imagenet\")\n",
    "# base_model.trainable = False\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     base_model,\n",
    "#     layers.GlobalAveragePooling2D(),\n",
    "#     layers.Dense(128, activation=\"relu\"),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(1, activation=\"sigmoid\")\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#               loss=\"binary_crossentropy\",\n",
    "#               metrics=[\"accuracy\"])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(train_data, validation_data=val_data, epochs=10)\n",
    "\n",
    "# # Plot loss and accuracy\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Loss over Epochs')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.title('Accuracy over Epochs')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d11fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:35:51.758226Z",
     "iopub.status.busy": "2025-02-05T16:35:51.757936Z",
     "iopub.status.idle": "2025-02-05T16:35:51.761296Z",
     "shell.execute_reply": "2025-02-05T16:35:51.760633Z"
    },
    "papermill": {
     "duration": 0.288617,
     "end_time": "2025-02-05T16:35:51.762601",
     "exception": false,
     "start_time": "2025-02-05T16:35:51.473984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save(\"model.h5\")\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # # Convert the model to TFLite\n",
    "# # converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# # tflite_model = converter.convert()\n",
    "\n",
    "# # # Save the TFLite model\n",
    "# # with open(\"model.tflite\", \"wb\") as f:\n",
    "# #     f.write(tflite_model)\n",
    "\n",
    "\n",
    "# # import tf2onnx\n",
    "\n",
    "# # # Convert to ONNX format\n",
    "# # onnx_model, _ = tf2onnx.convert.from_keras(model, output_path=\"model.onnx\")\n",
    "\n",
    "# # !pip install tensorflowjs\n",
    "# # import tensorflowjs as tfjs\n",
    "\n",
    "# # # Convert to TF.js format\n",
    "# # tfjs.converters.save_keras_model(model, \"tfjs_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e8bee",
   "metadata": {
    "papermill": {
     "duration": 0.347943,
     "end_time": "2025-02-05T16:35:52.396887",
     "exception": false,
     "start_time": "2025-02-05T16:35:52.048944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "833e41e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:35:52.960544Z",
     "iopub.status.busy": "2025-02-05T16:35:52.960120Z",
     "iopub.status.idle": "2025-02-05T16:35:52.963489Z",
     "shell.execute_reply": "2025-02-05T16:35:52.962835Z"
    },
    "papermill": {
     "duration": 0.287669,
     "end_time": "2025-02-05T16:35:52.964790",
     "exception": false,
     "start_time": "2025-02-05T16:35:52.677121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caa1c3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:35:53.528590Z",
     "iopub.status.busy": "2025-02-05T16:35:53.528086Z",
     "iopub.status.idle": "2025-02-05T16:35:53.531537Z",
     "shell.execute_reply": "2025-02-05T16:35:53.530844Z"
    },
    "papermill": {
     "duration": 0.289531,
     "end_time": "2025-02-05T16:35:53.532816",
     "exception": false,
     "start_time": "2025-02-05T16:35:53.243285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# yolo_model = YOLO(\"yolov8n-cls.pt\")\n",
    "# yolo_model.train(data=data_dir, epochs=10, imgsz=224, batch=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e87062",
   "metadata": {
    "papermill": {
     "duration": 0.279841,
     "end_time": "2025-02-05T16:35:54.165658",
     "exception": false,
     "start_time": "2025-02-05T16:35:53.885817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a67657",
   "metadata": {
    "papermill": {
     "duration": 0.27889,
     "end_time": "2025-02-05T16:35:54.725344",
     "exception": false,
     "start_time": "2025-02-05T16:35:54.446454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af522213",
   "metadata": {
    "papermill": {
     "duration": 0.293367,
     "end_time": "2025-02-05T16:35:55.320619",
     "exception": false,
     "start_time": "2025-02-05T16:35:55.027252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582c6bd",
   "metadata": {
    "papermill": {
     "duration": 0.285255,
     "end_time": "2025-02-05T16:35:55.903379",
     "exception": false,
     "start_time": "2025-02-05T16:35:55.618124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c291aaa",
   "metadata": {
    "papermill": {
     "duration": 0.285804,
     "end_time": "2025-02-05T16:35:56.541272",
     "exception": false,
     "start_time": "2025-02-05T16:35:56.255468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ad148",
   "metadata": {
    "papermill": {
     "duration": 0.281506,
     "end_time": "2025-02-05T16:35:57.104871",
     "exception": false,
     "start_time": "2025-02-05T16:35:56.823365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90a565",
   "metadata": {
    "papermill": {
     "duration": 0.281923,
     "end_time": "2025-02-05T16:35:57.670150",
     "exception": false,
     "start_time": "2025-02-05T16:35:57.388227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee9851",
   "metadata": {
    "papermill": {
     "duration": 0.279957,
     "end_time": "2025-02-05T16:35:58.301809",
     "exception": false,
     "start_time": "2025-02-05T16:35:58.021852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950e5d7",
   "metadata": {
    "papermill": {
     "duration": 0.277447,
     "end_time": "2025-02-05T16:35:58.859218",
     "exception": false,
     "start_time": "2025-02-05T16:35:58.581771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a557e9d",
   "metadata": {
    "papermill": {
     "duration": 0.276987,
     "end_time": "2025-02-05T16:35:59.413817",
     "exception": false,
     "start_time": "2025-02-05T16:35:59.136830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a30760",
   "metadata": {
    "papermill": {
     "duration": 0.277253,
     "end_time": "2025-02-05T16:35:59.968991",
     "exception": false,
     "start_time": "2025-02-05T16:35:59.691738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8253c",
   "metadata": {
    "papermill": {
     "duration": 0.284797,
     "end_time": "2025-02-05T16:36:00.600224",
     "exception": false,
     "start_time": "2025-02-05T16:36:00.315427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b8eaa8",
   "metadata": {
    "papermill": {
     "duration": 0.282248,
     "end_time": "2025-02-05T16:36:01.168338",
     "exception": false,
     "start_time": "2025-02-05T16:36:00.886090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b45ab6",
   "metadata": {
    "papermill": {
     "duration": 0.283245,
     "end_time": "2025-02-05T16:36:01.736210",
     "exception": false,
     "start_time": "2025-02-05T16:36:01.452965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83671e05",
   "metadata": {
    "papermill": {
     "duration": 0.285569,
     "end_time": "2025-02-05T16:36:02.382302",
     "exception": false,
     "start_time": "2025-02-05T16:36:02.096733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0085d18",
   "metadata": {
    "papermill": {
     "duration": 0.281486,
     "end_time": "2025-02-05T16:36:02.946946",
     "exception": false,
     "start_time": "2025-02-05T16:36:02.665460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b8bdf",
   "metadata": {
    "papermill": {
     "duration": 0.281929,
     "end_time": "2025-02-05T16:36:03.507710",
     "exception": false,
     "start_time": "2025-02-05T16:36:03.225781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3edd6",
   "metadata": {
    "papermill": {
     "duration": 0.278549,
     "end_time": "2025-02-05T16:36:04.065156",
     "exception": false,
     "start_time": "2025-02-05T16:36:03.786607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86207fa1",
   "metadata": {
    "papermill": {
     "duration": 0.280993,
     "end_time": "2025-02-05T16:36:04.692889",
     "exception": false,
     "start_time": "2025-02-05T16:36:04.411896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88841e5",
   "metadata": {
    "papermill": {
     "duration": 0.294992,
     "end_time": "2025-02-05T16:36:05.293683",
     "exception": false,
     "start_time": "2025-02-05T16:36:04.998691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c305e",
   "metadata": {
    "papermill": {
     "duration": 0.282062,
     "end_time": "2025-02-05T16:36:05.858063",
     "exception": false,
     "start_time": "2025-02-05T16:36:05.576001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f022023",
   "metadata": {
    "papermill": {
     "duration": 0.280288,
     "end_time": "2025-02-05T16:36:06.487615",
     "exception": false,
     "start_time": "2025-02-05T16:36:06.207327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5761053",
   "metadata": {
    "papermill": {
     "duration": 0.282208,
     "end_time": "2025-02-05T16:36:07.053642",
     "exception": false,
     "start_time": "2025-02-05T16:36:06.771434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f53ff3",
   "metadata": {
    "papermill": {
     "duration": 0.286158,
     "end_time": "2025-02-05T16:36:07.621236",
     "exception": false,
     "start_time": "2025-02-05T16:36:07.335078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da444177",
   "metadata": {
    "papermill": {
     "duration": 0.279425,
     "end_time": "2025-02-05T16:36:08.191705",
     "exception": false,
     "start_time": "2025-02-05T16:36:07.912280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135da10",
   "metadata": {
    "papermill": {
     "duration": 0.281702,
     "end_time": "2025-02-05T16:36:08.827135",
     "exception": false,
     "start_time": "2025-02-05T16:36:08.545433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1740f0f",
   "metadata": {
    "papermill": {
     "duration": 0.279599,
     "end_time": "2025-02-05T16:36:09.385862",
     "exception": false,
     "start_time": "2025-02-05T16:36:09.106263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011f119",
   "metadata": {
    "papermill": {
     "duration": 0.28029,
     "end_time": "2025-02-05T16:36:09.947079",
     "exception": false,
     "start_time": "2025-02-05T16:36:09.666789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f5179",
   "metadata": {
    "papermill": {
     "duration": 0.281194,
     "end_time": "2025-02-05T16:36:10.574789",
     "exception": false,
     "start_time": "2025-02-05T16:36:10.293595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ac585",
   "metadata": {
    "papermill": {
     "duration": 0.276655,
     "end_time": "2025-02-05T16:36:11.130222",
     "exception": false,
     "start_time": "2025-02-05T16:36:10.853567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87be20e",
   "metadata": {
    "papermill": {
     "duration": 0.277336,
     "end_time": "2025-02-05T16:36:11.691581",
     "exception": false,
     "start_time": "2025-02-05T16:36:11.414245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d99195",
   "metadata": {
    "papermill": {
     "duration": 0.279494,
     "end_time": "2025-02-05T16:36:12.253080",
     "exception": false,
     "start_time": "2025-02-05T16:36:11.973586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00679a",
   "metadata": {
    "papermill": {
     "duration": 0.283106,
     "end_time": "2025-02-05T16:36:12.881019",
     "exception": false,
     "start_time": "2025-02-05T16:36:12.597913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cece4a6",
   "metadata": {
    "papermill": {
     "duration": 0.281404,
     "end_time": "2025-02-05T16:36:13.441819",
     "exception": false,
     "start_time": "2025-02-05T16:36:13.160415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea14bd",
   "metadata": {
    "papermill": {
     "duration": 0.281448,
     "end_time": "2025-02-05T16:36:14.002431",
     "exception": false,
     "start_time": "2025-02-05T16:36:13.720983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd06672",
   "metadata": {
    "papermill": {
     "duration": 0.279319,
     "end_time": "2025-02-05T16:36:14.626232",
     "exception": false,
     "start_time": "2025-02-05T16:36:14.346913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a19131",
   "metadata": {
    "papermill": {
     "duration": 0.302779,
     "end_time": "2025-02-05T16:36:15.207867",
     "exception": false,
     "start_time": "2025-02-05T16:36:14.905088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca7841",
   "metadata": {
    "papermill": {
     "duration": 0.277232,
     "end_time": "2025-02-05T16:36:15.762990",
     "exception": false,
     "start_time": "2025-02-05T16:36:15.485758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2195166,
     "sourceId": 3667213,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2043430,
     "sourceId": 4516184,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3027905,
     "sourceId": 5206203,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13451.489879,
   "end_time": "2025-02-05T16:36:18.746387",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-05T12:52:07.256508",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
