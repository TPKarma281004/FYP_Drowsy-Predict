{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1770390,"sourceType":"datasetVersion","datasetId":1048759}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2 as cv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T12:14:34.376324Z","iopub.execute_input":"2025-07-14T12:14:34.377049Z","iopub.status.idle":"2025-07-14T12:14:34.381358Z","shell.execute_reply.started":"2025-07-14T12:14:34.377010Z","shell.execute_reply":"2025-07-14T12:14:34.380357Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Process raw data\n","metadata":{}},{"cell_type":"code","source":"# Path of the directory with raw images\nraw_dir = '/kaggle/input/mrl-dataset/train'\nfolders = ['Open_Eyes', 'Closed_Eyes']\n\n# Path of the directory where processed images will be stored\nprocessed_dir = '/kaggle/working'\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-14T12:14:41.041585Z","iopub.execute_input":"2025-07-14T12:14:41.041917Z","iopub.status.idle":"2025-07-14T12:14:41.046380Z","shell.execute_reply.started":"2025-07-14T12:14:41.041891Z","shell.execute_reply":"2025-07-14T12:14:41.045556Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Mean and std of ImageNet will be used to normalize the images\nmean = np.array([0.485, 0.456, 0.406])\nstd  = np.array([0.229, 0.224, 0.225])\n\nimages = []\nlabels = []\n\ndef process_image(img_path):\n    img = cv.imread(img_path)\n    if img is None:\n        print(f\"Error loading {img_path}.\")\n        return None\n    # Resize image to 224 x 224 as this image size is expected by ResNet or MobileNet which will be used for image classification\n    img = cv.resize(img, (224, 224))\n    # cv2 uses the BGR color format, so we convert it to the RGB format\n    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n    # Normalize the image values to range [0, 1]\n    img = img / 255.0\n    img = (img - mean) / std\n    return img\n\n\nfor label, folder in enumerate(folders):\n    folder_path = os.path.join(raw_dir, folder)\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)\n        img = process_image(file_path)\n        if img is not None:\n            images.append(img)\n            labels.append(label)\n\n# Convert images and labels to NumPy arrays\nimages = np.array(images)\nlabels = np.array(labels)\n\n# Save processed images and labels\nnp.save(os.path.join(processed_dir, \"images.npy\"), images)\nnp.save(os.path.join(processed_dir, \"labels.npy\"), labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T12:14:42.685098Z","iopub.execute_input":"2025-07-14T12:14:42.685390Z","iopub.status.idle":"2025-07-14T12:15:23.329689Z","shell.execute_reply.started":"2025-07-14T12:14:42.685369Z","shell.execute_reply":"2025-07-14T12:15:23.328910Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Load the processed dataset\nimages = np.load(os.path.join(processed_dir, \"images.npy\"))\nlabels = np.load(os.path.join(processed_dir, \"labels.npy\"))\n\n'''Split the dataset into train+val (80%) and test datasets (20%). The data is automatically shuffled. \nstratify=labels: the generated splits gave the same proprotion of labels as given by parameter \"labels\".'''\nimages_train_val, images_test, labels_train_val, labels_test = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n\n# Split the train_val dataset into train (75%) and val datasets (25%)\nimages_train, images_val, labels_train, labels_val = train_test_split(images_train_val, labels_train_val, test_size=0.25, random_state=42, stratify=labels_train_val)\n\nprint(f\"Train set size: {images_train.shape[0]}\")\nprint(f\"Validation set size: {images_val.shape[0]}\")\nprint(f\"Test set size: {images_test.shape[0]}\")\n\n# Save split data and labels\nnp.save(os.path.join(processed_dir, \"train_images.npy\"), images_train)\nnp.save(os.path.join(processed_dir, \"train_labels.npy\"), labels_train)\nnp.save(os.path.join(processed_dir, \"val_images.npy\"), images_val)\nnp.save(os.path.join(processed_dir, \"val_labels.npy\"), labels_val)\nnp.save(os.path.join(processed_dir, \"test_images.npy\"), images_test)\nnp.save(os.path.join(processed_dir, \"test_labels.npy\"), labels_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T12:16:03.851129Z","iopub.execute_input":"2025-07-14T12:16:03.851422Z","iopub.status.idle":"2025-07-14T12:16:14.074932Z","shell.execute_reply.started":"2025-07-14T12:16:03.851400Z","shell.execute_reply":"2025-07-14T12:16:14.072433Z"}},"outputs":[{"name":"stdout","text":"Train set size: 2400\nValidation set size: 800\nTest set size: 800\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Finetune ResNet50","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras import models, layers, Sequential\n\ndef get_resnet50_model(variant='base'):\n    # Load the ResNet50 model pretrained on ImageNet\n    base_model = ResNet50(include_top=False, input_shape=(224, 224, 3))\n    train_from = 150\n\n    if variant == 'finetune':\n        base_model.trainable = True\n        for layer in base_model.layers[:train_from]:\n            layer.trainable = False\n    else:\n        # Freeze all layers\n        base_model.trainable = False\n    \n    model_append = [layers.GlobalAveragePooling2D()]\n    model_append.append(layers.Dense(1, activation='sigmoid'))\n    model = Sequential([base_model] + model_append)\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T12:19:14.029419Z","iopub.execute_input":"2025-07-14T12:19:14.030067Z","iopub.status.idle":"2025-07-14T12:19:14.035827Z","shell.execute_reply.started":"2025-07-14T12:19:14.030040Z","shell.execute_reply":"2025-07-14T12:19:14.035127Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC, F1Score\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n\n# Load train dataset\nX_train = np.load(os.path.join(processed_dir, \"train_images.npy\"))\ny_train = np.load(os.path.join(processed_dir, \"train_labels.npy\"))\n# Reshape y_train (num_train_examples,) to have the same shape as model predictions in tf (num_train_examples, 1)\ny_train = y_train.reshape(-1, 1)\n\n# Load validation dataset\nX_val = np.load(os.path.join(processed_dir, \"val_images.npy\"))\ny_val = np.load(os.path.join(processed_dir, \"val_labels.npy\"))\n# Reshape y_val (num_val_examples,) to have the same shape as model predictions in tf (num_val_examples, 1)\ny_val = y_val.reshape(-1, 1)\n\n# Choose model variant: 'base', 'finetune'\nmodel_variant = 'finetune'\n# Load ResNet50 model\nmodel = get_resnet50_model(variant=model_variant)\n\n# Configure model settings for training\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy(), Precision(), Recall(), AUC(), F1Score(threshold=0.5)])\n\n# Callbacks\n# Create the EarlyStopping callback\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(f\"/kaggle/working/{model_variant}.h5\", save_best_only=True)\n\n# Train modified ResNet50\nhistory = model.fit(X_train, y_train, validation_data=[X_val, y_val], batch_size=32, epochs=15, callbacks=[early_stop, checkpoint])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T12:19:47.242398Z","iopub.execute_input":"2025-07-14T12:19:47.243032Z","iopub.status.idle":"2025-07-14T12:23:00.795112Z","shell.execute_reply.started":"2025-07-14T12:19:47.243010Z","shell.execute_reply":"2025-07-14T12:23:00.794401Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1752495591.672439      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1752495591.673147      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1752495621.758063     103 service.cc:148] XLA service 0x79cfb8003b50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1752495621.759286     103 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1752495621.759315     103 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1752495623.866618     103 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 1/75\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:31\u001b[0m 28s/step - auc: 0.7314 - binary_accuracy: 0.7188 - f1_score: 0.7692 - loss: 0.6539 - precision: 0.6250 - recall: 1.0000","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752495632.033940     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 259ms/step - auc: 0.9742 - binary_accuracy: 0.9260 - f1_score: 0.9297 - loss: 0.1814 - precision: 0.9107 - recall: 0.9517 - val_auc: 0.9991 - val_binary_accuracy: 0.6175 - val_f1_score: 0.3806 - val_loss: 0.4657 - val_precision: 1.0000 - val_recall: 0.2350\nEpoch 2/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 149ms/step - auc: 0.9999 - binary_accuracy: 0.9959 - f1_score: 0.9959 - loss: 0.0179 - precision: 0.9948 - recall: 0.9970 - val_auc: 0.9936 - val_binary_accuracy: 0.8737 - val_f1_score: 0.8879 - val_loss: 0.3512 - val_precision: 0.7984 - val_recall: 1.0000\nEpoch 3/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 152ms/step - auc: 0.9997 - binary_accuracy: 0.9898 - f1_score: 0.9896 - loss: 0.0236 - precision: 0.9948 - recall: 0.9845 - val_auc: 1.0000 - val_binary_accuracy: 0.9987 - val_f1_score: 0.9988 - val_loss: 0.0059 - val_precision: 0.9975 - val_recall: 1.0000\nEpoch 4/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - auc: 0.9989 - binary_accuracy: 0.9942 - f1_score: 0.9940 - loss: 0.0194 - precision: 0.9916 - recall: 0.9964 - val_auc: 1.0000 - val_binary_accuracy: 0.8250 - val_f1_score: 0.7879 - val_loss: 0.3134 - val_precision: 1.0000 - val_recall: 0.6500\nEpoch 5/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 158ms/step - auc: 0.9996 - binary_accuracy: 0.9901 - f1_score: 0.9901 - loss: 0.0258 - precision: 0.9955 - recall: 0.9848 - val_auc: 1.0000 - val_binary_accuracy: 0.9975 - val_f1_score: 0.9975 - val_loss: 0.0039 - val_precision: 1.0000 - val_recall: 0.9950\nEpoch 6/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 161ms/step - auc: 0.9999 - binary_accuracy: 0.9964 - f1_score: 0.9962 - loss: 0.0114 - precision: 0.9950 - recall: 0.9974 - val_auc: 1.0000 - val_binary_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0013 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 7/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 151ms/step - auc: 1.0000 - binary_accuracy: 0.9974 - f1_score: 0.9973 - loss: 0.0042 - precision: 0.9957 - recall: 0.9989 - val_auc: 1.0000 - val_binary_accuracy: 0.9987 - val_f1_score: 0.9987 - val_loss: 0.0020 - val_precision: 1.0000 - val_recall: 0.9975\nEpoch 8/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 152ms/step - auc: 1.0000 - binary_accuracy: 0.9993 - f1_score: 0.9993 - loss: 0.0026 - precision: 1.0000 - recall: 0.9986 - val_auc: 1.0000 - val_binary_accuracy: 0.9987 - val_f1_score: 0.9988 - val_loss: 0.0024 - val_precision: 0.9975 - val_recall: 1.0000\nEpoch 9/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 169ms/step - auc: 1.0000 - binary_accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - precision: 1.0000 - recall: 1.0000 - val_auc: 1.0000 - val_binary_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.0903e-04 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 10/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 162ms/step - auc: 1.0000 - binary_accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4199e-04 - precision: 1.0000 - recall: 1.0000 - val_auc: 1.0000 - val_binary_accuracy: 0.9987 - val_f1_score: 0.9988 - val_loss: 0.0016 - val_precision: 0.9975 - val_recall: 1.0000\nEpoch 11/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 163ms/step - auc: 1.0000 - binary_accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.3974e-04 - precision: 1.0000 - recall: 1.0000 - val_auc: 1.0000 - val_binary_accuracy: 0.9837 - val_f1_score: 0.9835 - val_loss: 0.0456 - val_precision: 1.0000 - val_recall: 0.9675\nEpoch 12/15\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 158ms/step - auc: 1.0000 - binary_accuracy: 0.9998 - f1_score: 0.9998 - loss: 6.3484e-04 - precision: 1.0000 - recall: 0.9995 - val_auc: 1.0000 - val_binary_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.9188e-04 - val_precision: 1.0000 - val_recall: 1.0000\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Load test dataset\nX_test = np.load(\"/kaggle/working/test_images.npy\")\ny_test = np.load(\"/kaggle/working/test_labels.npy\")\n# Reshape y_test (num_test_examples,) to have the same shape as model predictions in tf (num_test_examples, 1)\ny_test = y_test.reshape(-1, 1)\n\n# Load the updated resnet model\nmodel = load_model(\"/kaggle/working/finetune.h5\")\n\n# Evaluate on the test dataset\nresults = model.evaluate(X_test, y_test, batch_size=32, verbose=1)\n\n# Predict labels\ny_pred_probs = model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Print classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, target_names=[\"Open\", \"Closed\"]))\n\n# Print confusion matrix\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T12:24:51.754989Z","iopub.execute_input":"2025-07-14T12:24:51.755301Z","iopub.status.idle":"2025-07-14T12:25:14.014057Z","shell.execute_reply.started":"2025-07-14T12:24:51.755284Z","shell.execute_reply":"2025-07-14T12:25:14.013260Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 1.0000 - binary_accuracy: 0.9993 - f1_score: 0.9993 - loss: 8.1286e-04 - precision: 1.0000 - recall: 0.9985\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        Open       1.00      1.00      1.00       400\n      Closed       1.00      1.00      1.00       400\n\n    accuracy                           1.00       800\n   macro avg       1.00      1.00      1.00       800\nweighted avg       1.00      1.00      1.00       800\n\n\nConfusion Matrix:\n[[400   0]\n [  1 399]]\n","output_type":"stream"}],"execution_count":10}]}